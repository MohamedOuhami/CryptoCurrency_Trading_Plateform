version: "3.8"

services:
    # configuration manager for NiFi
  zookeeper:
    image: confluentinc/cp-zookeeper:7.4.0
    hostname: zookeeper
    container_name: zookeeper_nifi
    ports:
      - "2181:2181"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    healthcheck:
      test: ["CMD", "echo", "ruok", "|", "nc", "localhost", "2181"]
      interval: 20s
      timeout: 20s
      retries: 20
    networks:
      - my_persistent_network
# version control for nifi flows
  registry:
      hostname: myregistry
      container_name: registry_container_persistent
      image: 'apache/nifi-registry:1.19.1'
      restart: on-failure
      ports:
          - "18080:18080"
      environment:
          - LOG_LEVEL=INFO
          - NIFI_REGISTRY_DB_DIR=/opt/nifi-registry/nifi-registry-current/database
          - NIFI_REGISTRY_FLOW_PROVIDER=file
          - NIFI_REGISTRY_FLOW_STORAGE_DIR=/opt/nifi-registry/nifi-registry-current/flow_storage
      volumes:
          - ./nifi_registry/database:/opt/nifi-registry/nifi-registry-current/database
          - ./nifi_registry/flow_storage:/opt/nifi-registry/nifi-registry-current/flow_storage
      networks:
          - my_persistent_network

# data extraction, transformation and load service
  spark-worker:
    container_name: spark-worker-elasticbean
    image: bitnami/spark:3.5
    command: bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077
    depends_on:
      - spark-master
    environment:
      SPARK_MODE: worker
      SPARK_WORKER_CORES: 2
      SPARK_WORKER_MEMORY: 2g
      SPARK_MASTER_URL: spark://spark-master:7077
    networks:
      - my_persistent_network
      
  spark-master:
    container_name: spark-master-elasticsearch
    image: bitnami/spark:3.5
    command: bin/spark-class org.apache.spark.deploy.master.Master
    ports:
      - "9090:8080"
      - "7077:7077"
    networks:
      - my_persistent_network
    volumes:
      - ./binance_data/dist/elasticsearch-hadoop-8.7.1.jar:/opt/bitnami/spark/jars/elasticsearch-hadoop-8.7.1.jar
      
  nifi:
      hostname: mynifi
      container_name: nifi_container_persistent
      image: 'apache/nifi:1.19.1' 
      restart: on-failure
      ports:
          - '8091:8080'
      environment:
          - NIFI_WEB_HTTP_PORT=8080
          - NIFI_CLUSTER_IS_NODE=true
          - NIFI_CLUSTER_NODE_PROTOCOL_PORT=8082
          - NIFI_ZK_CONNECT_STRING=zookeeper_nifi:2181
          - NIFI_ELECTION_MAX_WAIT=30 sec
          - NIFI_SENSITIVE_PROPS_KEY='12345678901234567890A'
      healthcheck:
          test: "${DOCKER_HEALTHCHECK_TEST:-curl localhost:8091/nifi/}"
          interval: "60s"
          timeout: "3s"
          start_period: "5s"
          retries: 5
      volumes:
          - ./nifi/database_repository:/opt/nifi/nifi-current/database_repository
          - ./nifi/flowfile_repository:/opt/nifi/nifi-current/flowfile_repository
          - ./nifi/content_repository:/opt/nifi/nifi-current/content_repository
          - ./nifi/provenance_repository:/opt/nifi/nifi-current/provenance_repository
          - ./nifi/state:/opt/nifi/nifi-current/state
          - ./nifi/logs:/opt/nifi/nifi-current/logs
          # uncomment the next line after copying the /conf directory from the container to your local directory to persist NiFi flows
          #- ./nifi/conf:/opt/nifi/nifi-current/conf
      networks:
          - my_persistent_network

  # Elastic Search
  setup:
    image: docker.elastic.co/elasticsearch/elasticsearch:${STACK_VERSION}
    user: "0"
    command: >
      bash -c '
        if [ x${ELASTIC_PASSWORD} == x ]; then
          echo "Set the ELASTIC_PASSWORD environment variable in the .env file";
          exit 1;
        fi;
        echo "Waiting for Elasticsearch availability";
        until curl -s http://es01:9200 | grep -q "missing authentication credentials"; do sleep 30; done;
        echo "All done!";
      '
    healthcheck:
      test: ["CMD-SHELL", "curl -s http://es01:9200 | grep -q 'missing authentication credentials'"]
      interval: 1s
      timeout: 5s
      retries: 120

  es01:
    depends_on:
      setup:
        condition: service_healthy
    image: docker.elastic.co/elasticsearch/elasticsearch:${STACK_VERSION}
    volumes:
      - esdata01:/usr/share/elasticsearch/data
    ports:
      - ${ES_PORT}:9200
    environment:
      - node.name=es01
      - cluster.name=${CLUSTER_NAME}
      - cluster.initial_master_nodes=es01,es02
      - discovery.seed_hosts=es02
      - ELASTIC_PASSWORD=${ELASTIC_PASSWORD}
      - bootstrap.memory_lock=true
      - xpack.security.enabled=false
      - xpack.license.self_generated.type=${LICENSE}
      - xpack.ml.use_auto_machine_memory_percent=true
    mem_limit: ${MEM_LIMIT}
    ulimits:
      memlock:
        soft: -1
        hard: -1
    healthcheck:
      test:
        [
          "CMD-SHELL",
          "curl -s http://localhost:9200 | grep -q 'missing authentication credentials'",
        ]
      interval: 10s
      timeout: 10s
      retries: 120
    networks:
      - my_persistent_network

  es02:
    depends_on:
      - es01
    image: docker.elastic.co/elasticsearch/elasticsearch:${STACK_VERSION}
    volumes:
      - esdata02:/usr/share/elasticsearch/data
    environment:
      - node.name=es02
      - cluster.name=${CLUSTER_NAME}
      - cluster.initial_master_nodes=es01,es02
      - discovery.seed_hosts=es01
      - ELASTIC_PASSWORD=${ELASTIC_PASSWORD}
      - bootstrap.memory_lock=true
      - xpack.security.enabled=false
      - xpack.license.self_generated.type=${LICENSE}
      - xpack.ml.use_auto_machine_memory_percent=true
    mem_limit: ${MEM_LIMIT}
    ulimits:
      memlock:
        soft: -1
        hard: -1
    healthcheck:
      test:
        [
          "CMD-SHELL",
          "curl -s http://localhost:9200 | grep -q 'missing authentication credentials'",
        ]
      interval: 10s
      timeout: 10s
      retries: 120
    networks:
      - my_persistent_network
networks:
  my_persistent_network:
    driver: bridge

volumes:
  certs:
    driver: local
  esdata01:
    driver: local
  esdata02:
    driver: local
  metricbeatdata01:
    driver: local
  filebeatdata01:
    driver: local
  logstashdata01:
    driver: local
  conf:
  content:
  db:
  flowfile:
  provenance:
  logs:
  data: